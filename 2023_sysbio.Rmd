---
title: "More data != more better"
subtitle: "The pitfalls of using high dimensional genomic data for source attribution"
author: "Jonathan Marshall, Helen Smith"
output:
  xaringan::moon_reader:
    css: [default, default-fonts, "custom.css"]
#    mathjax: "https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-MML-AM_CHTML"
    nature:
      highlightStyle: tomorrow
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      slideNumberFormat: |
        <div class="progress-bar-container">
          <div class="progress-bar" style="width: calc(%current% / %total% * 100%);" />
        </div>
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(tidyverse)
library(lubridate)
library(meshblocknz)
library(knitr)
library(mgcv)
library(sf)
library(shiny)
library(gtools)
library(Manu)
library(colorspace)
theme_set(theme_minimal(base_size=13))
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE,
                      fig.retina = 3, fig.align='center',
                      fig.dim=c(4.8,4.8), out.width='100%', dev.args=list(bg="transparent"))

#theme_update(theme(plot.background = element_rect(fill = "transparent", color = NA)))
opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE, fig.height = 5, fig.align='center', bg='transparent', dev.args=list(bg='transparent'))
attr_data <- read.csv("data/dirichlet_island/attribution_data.csv") %>%
  filter(Source != "Human" | Year >= 2008)
sts = attr_data %>%
  group_by(ST) %>% count(Source) %>% spread(Source, n, fill=0) %>%
  ungroup()
sts_ur = attr_data %>% filter(Source == "Human") %>%
  group_by(ST) %>% count(UR2006) %>% ungroup()
nz = read_csv("data/dirichlet_island/dhb_cases.csv") %>%
  mutate(Date = dmy(paste(1, Month, Year))) %>%
  filter(Year >= 2006) %>% group_by(Date) %>%
  summarise(Count = sum(Count, na.rm=TRUE), Population = sum(PopulationInterpolated, na.rm=TRUE)) %>%
  mutate(Rate = Count/Population*100000*12)

attribution = read.csv("data/dirichlet_island/attribution.csv")
alpha = function(col, alpha) { rgb(t(col2rgb(col)/255), alpha=alpha) }
par(mar=c(3,3,2,1), mgp=c(2,.7,0), tck=-.03)
ax_col = "grey20"
fig_width = 10

source_cols <- c(Poultry="brown", Ruminants="steelblue2", Other="plum4", Water="green4")


# Gene stuff from NZSA talk here
max_genes <- read_csv("data/max_genes_by_distance.csv") |>
  mutate(dist_to_nearest = as_factor(dist_to_nearest) |> fct_rev()) |>
  mutate(sum = humans+genes, prod=humans*genes) |> 
  group_by(dist_to_nearest) |>
  mutate(max_sum = sum == max(sum), max_prod = prod == max(prod),
         max_equal = humans == genes) |>
  ungroup()

plot_right <- ggplot(max_genes) +
  geom_line(aes(x=humans, y=genes, col=dist_to_nearest, size=dist_to_nearest == 0)) +
  scale_colour_manual(values=c(scales::alpha(get_pal('Hoiho')[-3], 0.7), 'black')) +
  scale_size_manual(values=c(0.5, 1)) +
  guides(size='none', col=guide_legend(nrow=1)) +
  labs(x="Number of humans",
       y="Number of genes",
       col="SNPs") +
  theme(legend.position='bottom')

plot_dark <- plot_right +
  theme(rect = element_rect(fill='transparent'),
        #panel.background = element_rect(fill='transparent'),
        panel.grid = element_line(colour='grey30'),
        text = element_text(colour='white'),
        axis.text = element_text(colour='white')) +
  scale_colour_manual(values=c(get_pal('Hoiho')[-3], 'white')) +
  scale_size_manual(values=c(0.8, 1))
```

class: middle, inverse

# Source attribution

---

## Where are people getting campylobacteriosis from?

<div align="center">
<span class='inline'>
  <img src="figures/Chicken-25.png" alt="Drawing" style="width: 180px;" align="center">
  <img src="figures/sheep.png" alt="Drawing" style="width: 250px;" align="center">
  <img src="figures/cow-07.png" alt="Drawing" style="width: 400px;" align="center">
</span>
</div>

---

## MLST distribution of human cases

```{r, mlst dist human, fig.dim=c(10, 5)}
# top 20 or so isolates
top20 <- sts %>% mutate(ST = fct_lump(factor(ST), n=20, w=Human)) %>% gather(Source, Count, -ST) %>%
  group_by(ST, Source) %>% summarise(Count = sum(Count)) %>% group_by(Source) %>% mutate(Count = Count/sum(Count)) %>% ungroup() %>%
  spread(Source, Count) %>% mutate(ST = fct_reorder(ST, Human, .fun = identity, .desc=TRUE),
                                   ST = fct_relevel(ST, "Other", after = 23)) %>%
  gather(Source, Count, -ST, -Human) %>%
  mutate(Source = fct_relevel(Source, "Other", after=2)) %>%
  mutate(Colour = ST == "Other")

top_humans <- top20 %>% select(Human, ST, Colour) %>% unique()
ggplot(top_humans, aes(x=ST, y=Human, fill=Colour)) + 
  geom_col() +
  scale_fill_manual(values=c("steelblue", "grey60")) +
  scale_y_continuous("Percent human cases", labels = scales::percent, expand=c(0,0)) + 
  coord_cartesian(ylim = c(0,0.25)) +
  guides(fill='none') +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 90, vjust=0.5))
```

---

## MLSTs are source specific

```{r source_specific_mlst, fig.dim=c(10, 5)}
ggplot(top20, aes(x=ST, y=Count, fill=Colour)) + geom_col(data=top_humans, aes(y=Human), alpha=0.3) + geom_col(aes(y=Count)) +
  scale_fill_manual(values=c("steelblue", "grey60")) +
  scale_y_continuous("Percent isolates", labels = scales::percent, expand=c(0,0)) +
  coord_cartesian(ylim = c(0,0.25)) +
  facet_wrap(~Source) +
  guides(fill='none') +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 90, vjust=0.5))
```

---

## Assume human types are a mix of source types

<iframe src="https://shiny.massey.ac.nz/jcmarsha/OHA2019/" style="border: none;"></iframe>

---

## Adding statistics

.big-math[
$$P(\mathsf{Human~cases}) = \prod_h P(\mathsf{st}_h)$$
]

---

## Adding statistics

.big-math[
$$P(\mathsf{st}_h) = \sum_j P(\mathsf{st}_h~\mathsf{from~source}_j) P(\mathsf{source}_j)$$
]

---

## Adding statistics

.big-math[
$$P(\mathsf{st}) = \sum_j \underbrace{P(\mathsf{st}_h~\mathsf{from~source}_j)}_\text{genomic model} \underbrace{P(\mathsf{source}_j)}_\text{attribution to source}$$
]

---

## Asymmetric Island model | D. Wilson (2009)

Assume that genotypes arise from two or more homogeneous mixing populations
where we have

- **Mutation**, where novel alleles are produced.

- **Recombination**, where the allele at a given locus has been observed before, but
not in this allelic profile (i.e. the alleles come from at least two different genotypes).

- **Migration** between sources of genotypes and alleles.

---

## Asymmetric Island model

We model $P(\mathsf{st}_h~\mathsf{from~source}_j)$ via:

$$P(\mathsf{st}_h \mid j,X) = \sum_{c\in X} \frac{M_{S_cj}}{N_{S_c}} \prod_{l=1}^7 \left\{\begin{array}{ll}\mu_j & \mbox{if }\mathsf{st}_h^{l}\mbox{ is novel,}\\(1-\mu_j)R_j\sum_{k=1}^J M_{kj}f^l_{\mathsf{st}_h^lk} & \mbox{if }\mathsf{st}_h^{l}\neq c^l,\\(1-\mu_j)\left[1 - R_j(1 - \sum_{k=1}^J M_{kj}f^l_{\mathsf{st}_h^lk})\right] & \mbox{if }\mathsf{st}_h^{l}=c^l\end{array}\right.$$

- $c \in X$ are candidate sequences from which $\mathsf{st}_h$ evolved (all sequences other than $\mathsf{st}_h$).
- $S_c$ is the source where candidate sequence $c$ was observed.
- $N_{S_c}$ is the number of types observed on source $S_c$.
- $\mu_j$ be the probability of a novel mutant allele from source $j$.
- $R_j$ be the probability that a type has undergone recombination in source $j$.
- $M_{kj}$ be the probability of an allele migrating from source $k$ to $j$.
- $f^l_{ak}$ be the frequency with which allele $a$ has been observed at locus $l$ in those genotypes sampled from source $k$.

---

.left-code[
## Attribution results

- Use the source isolates to estimate mutation, recombination and migration parameters via MCMC.

- Using these estimates, compute $P(\mathsf{st}_h~\mathsf{from~source}_j)$ for the observed human sequences (even those unobserved on the sources).

- Finally use MCMC to estimate the attribution proportions.
]

.right-plot[
```{r}
source_cols2 <- c(Poultry = "brown", Beef = "steelblue4", Sheep = "steelblue1")

attr <- read_csv("data/dirichlet_island/many_genes_per_source.csv")
attr |>
  filter(Genes == "MLST") |>
  pivot_wider(names_from=quantile, values_from=value) |>
  ggplot() +
  geom_boxplot(aes(x=Source, lower = `0.25`, upper=`0.75`, ymin=`0.025`, ymax=`0.975`, middle=`0.5`, fill=Source), stat="identity", alpha=0.7, width=0.6) +
  scale_y_continuous(name="Attributed cases", labels=scales::percent_format(), limits=c(0,1), expand=c(0,0)) +
  scale_fill_manual(values = source_cols2) +
  guides(fill='none', col='none') +
  theme(axis.title.x = element_blank(),
        legend.position = c(0.90,0.89),
        legend.title = element_blank())
```
]

---

class: middle, inverse

# What if we have more genes?

---

.left-code[
## What if we have more genes?

- Recent studies (SACNZ) have used whole genome sequencing, and looked to see if we can distinguish cattle versus sheep.

- In theory the Island model should still work.

- But it... **doesn't :(**
]

.right-plot[
```{r}
best_attr <- attr %>% filter(str_detect(Genes, "Best"), str_detect(Data, "Full")) %>%
  extract(Genes, into='Genes', regex="([0-9]+)", convert=TRUE) %>%
  spread(quantile, value)

ggplot(best_attr, aes(x=Genes, y=`0.5`, fill=Source)) +
  geom_ribbon(aes(ymin=`0.025`, ymax=`0.975`), alpha=0.3) +
  geom_ribbon(aes(ymin=`0.25`, ymax=`0.75`), alpha=0.3) +
  geom_line(lwd=1, aes(col=Source)) +
  scale_y_continuous("Attribution of human cases", labels = scales::percent, expand=c(0,0), limits = c(-1,1)) +
  coord_cartesian(ylim = c(0,1)) +
  scale_x_continuous(limits = c(5,100), expand=c(0,0)) +
  scale_colour_manual(values = source_cols2) +
  scale_fill_manual(values = source_cols2) +
  theme(legend.position='bottom')
```
]

---

.left-code[
## Stabilising attribution

- Small differences in the mutation and recombination rates across sources are amplified in the likelihood.

- Everything ends up being assigned to the source with the lowest diversity.

- Stabilise by assuming recombination and mutation probabilities are the same across all sources.
]

.right-plot[
```{r}
common_attr <- read_csv("data/dirichlet_island/many_genes_common.csv")
common_best <- common_attr %>% filter(str_detect(Genes, "Best"), str_detect(Data, "Full")) %>%
  extract(Genes, into='Genes', regex="([0-9]+)", convert=TRUE) %>%
  spread(quantile, value)

ggplot(common_best, aes(x=Genes, y=`0.5`, fill=Source)) +
  geom_ribbon(aes(ymin=`0.025`, ymax=`0.975`), alpha=0.3) +
  geom_ribbon(aes(ymin=`0.25`, ymax=`0.75`), alpha=0.3) +
  geom_line(lwd=1, aes(col=Source)) +
  scale_y_continuous("Attribution of human cases", labels = scales::percent, expand=c(0,0), limits = c(-1,1)) +
  coord_cartesian(ylim = c(0,1)) +
  scale_x_continuous(limits = c(5,100), expand=c(0,0)) +
  scale_colour_manual(values = source_cols2) +
  scale_fill_manual(values = source_cols2) +
  theme(legend.position='bottom')
```
]

---

## Are the MLST genes special?

Choose 7 genes at random and compare with MLST

```{r, fig.dim=c(9,4.5), out.width='90%'}
random_attr <- common_attr %>% filter(str_detect(Genes, "Random"), str_detect(Data, "Full")) %>%
  extract(Genes, into="Genes", regex="([0-9]+)", convert=TRUE) %>%
  mutate(Genes = sprintf("R%02i", Genes)) %>%
  bind_rows(common_attr %>% filter(str_detect(Genes, "^MLST"), str_detect(Data, "Full"))) %>%
  spread(quantile, value)
ggplot(random_attr, aes(x=Genes, y=`0.5`, fill=Source)) +
  geom_linerange(aes(ymin=`0.025`, ymax=`0.975`), col='black') +
  geom_linerange(aes(ymin=`0.25`, ymax=`0.75`, col=Source), lwd=2) +
  geom_point(size=2, shape=21, col='black') +
  scale_y_continuous("Attribution of human cases", labels = scales::percent, expand=c(0,0), limits=c(0,1)) +
 # scale_x_discrete(limits = c(0,100), expand=c(0,0)) +
  scale_colour_manual(values = source_cols2) +
  scale_fill_manual(values = source_cols2) +
  guides(col='none', fill='none') +
  theme(axis.title.x = element_blank())
```

---

## So where are we?

- We have 1343 core genes available to us.

- Our goal is to classify human isolates to their most likely source.

- Existing models break if we use too many genes; when we fix them, the attribution is pretty much the same as using MLST.

- Picking 7 random genes is just as good as MLST; so the genes are correlated.

- **Why not try some machine learning techniques that cope with high dimensional, correlated predictors?**

---

class: middle, inverse

# Random Forests

---

## Can we use a Random Forest?

- Random forests are perfect for classification problems with a large number of potentially correlated predictors!

- Train the forest on the source isolates, and predict on the human isolates - voila!

- But, we have another two problems!

---

.left-code[
## Problem 1: High cardinality categorical predictors.

- When we build a tree, at each branching point, we need to choose a gene and decide which alleles should go
down each branch in order to best separate the sources.

- Need to determine the subset of alleles assigned to the left branch.

- The number of subsets to consider is $2^{K-1}$ where $K$ is the number of alleles.

- The median $K$ is 48, so this is computationally infeasible.
]

.right-plot[
```{r}
dat <- data.frame(y = c(2,3,6, 7, 9), x = 1:5)
library(rpart)
rp <- rpart(y ~ x, data=dat, control=list(minsplit=1, cp = 0.000001, minbucket=1))
plot(rp)
```

]
---

.left-code[
## Problem 2: Unique alleles

- Lots of alleles are unique to the test set (we only see them in humans).

- We could ignore them, but it'll dramatically reduce the size of our dataset.

- Lots of the 'unique alleles' are really similar (one SNP difference) from another
allele we have seen before.
]

.right-plot[
```{r}
plot_right
```
]

---

class: inverse, middle

# Encoding categorical variables

---

## Encoding categorical variables as numeric

- The alleles are just numbers, so why not treat them as such?

- The trees and forest can split a numeric variable wherever they like, so order maybe doesn't matter much?

- Any allele we haven't seen is already encoded as some other number.

---

## Numeric encoding: Consequences

- The alleles are already numeric, so just treat them as numbers.

- Allele numbers are defined based on the order that isolates are submitted to PubMLST.

- Researchers do not submit isolates randomly to PubMLST. They're often done in 'chunks' of isolates from the same source.

- So consecutive allele numbers often belong to the same source.

- A tree based model will exploit this well!

```{r, fig.dim=c(10,2)}
camp0864 <- read_csv("data/camp0864.csv")
camp0864 |> arrange(Allele) |> pull(Source) |> rle() -> foo
dat_for_plot <- tibble(n = foo$lengths, source = foo$values) |>
  slice(40:60) |> uncount(n) |> tibble::rowid_to_column() |>
  mutate(source = case_when(source == "Chicken" ~ "Poultry",
                            source == "Sheep" ~ "Ruminants",
                            source == "Cattle" ~ "Other",
                            TRUE ~ "Water"))

ggplot(dat_for_plot) +
  geom_rect(aes(xmin=rowid, xmax=rowid+1, ymin=0, ymax=1, fill=source), col='transparent') +
  guides(fill='none') +
  scale_fill_manual(values = source_cols) +
  labs(x="Allele", y=NULL,
       title="Alleles by source for CAMP0864") +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank())
```

---

.left-code[
## Numeric encoding: Consequences

Arning et. al.<sup>1</sup> used this encoding.

Results from their work are less impressive when we randomise the
allele labels.

.footnote[[1] https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1009436]
]

.right-plot[
```{r, fig.dim=c(4.8,4.2)}
arning <- read_csv("data/arning_shuffle.csv") |> mutate(Method = fct_recode(Method, Published = "Paper Order", Randomised = "Reshuffled")) |>
  mutate(Measure = fct_recode(Measure, `Positive Predictive Value` = "Precision", Sensitivity = "Recall"))
ggplot(arning) +
  geom_point(aes(x=Labels, y=value, col=Method), position=position_dodge(width=0.25)) +
  facet_wrap(vars(Measure), nrow=2) +
  labs(x=NULL, y=NULL, col=NULL) +
  theme(legend.position = 'bottom') +
  scale_colour_manual(values = c(Published = 'black', Randomised = 'darkred')) +
  scale_y_continuous(limits = c(0,1))
```
]

---

## Target encoding

.left-code[
- For 2 sources we can do it much faster via **target encoding**.

- For each gene, get the allele by class contingency table.

- Convert to proportions.

- Order the alleles by the proportion in class A and treat it as ordinal.

- We thus have a numeric variable so need only consider $K-1$ possible split points rather than $2^{K-1}$.
]

.right-plot[
```{r}
set.seed(3)
tab <- data.frame(prop = runif(5), count=rpois(5, lambda=10)) |>
  mutate(Allele = 1:5, A = round(prop*count), B = count-A) |>
  select(Allele, A, B)

tab |> knitr::kable()
```
]

---

## Target encoding

.left-code[
- For 2 sources we can do it much faster via **target encoding**.

- For each gene, get the allele by class contingency table.

- Convert to proportions.

- Order the alleles by the proportion in class A and treat it as ordinal.

- We thus have a numeric variable so need only consider $K-1$ possible split points rather than $2^{K-1}$.
]

.right-plot[
```{r}
tab2 <- tab |> pivot_longer(A:B) |> group_by(Allele) |> mutate(value = round(value/sum(value), 2)) |> pivot_wider()
tab2 |> knitr::kable()
```
]

---

## Target encoding

.left-code[
- For 2 sources we can do it much faster via **target encoding**.

- For each gene, get the allele by class contingency table.

- Convert to proportions.

- Order the alleles by the proportion in class A and treat it as ordinal.

- We thus have a numeric variable so need only consider $K-1$ possible split points rather than $2^{K-1}$.
]

.right-plot[
```{r}
tab2 |> arrange(A) |> knitr::kable()
```
]

---

## More than 2 sources

.left-code[
- Coppersmith (1999) extended this to multiple sources.

- Order by the scores of the first principal component of the proportioned contingency table.

- It's not perfect (not equivalent to the 2-partition) but works fairly well, and again means just $K-1$ split points.

- This is used in `ranger` in R.
]

.right-plot[
```{r}
set.seed(4)
tab3 <- data.frame(allele = 1:7, size = rpois(7, lambda=10)) |>
  mutate(count = map(size, ~rmultinom(1, ., prob = c(1,1,1)))) |>
  unnest(count) |>
  group_by(allele) |>
  mutate(row = row_number()) |>
  pivot_wider(names_from=row, values_from=count) |>
  select(-size) |> set_names(c("allele", LETTERS[1:3])) |>
  as.data.frame()

tab3 |> knitr::kable()
```
]

---

## More than 2 sources

.left-code[
- Coppersmith (1999) extended this to multiple sources.

- Order by the scores of the first principal component of the proportioned contingency table.

- It's not perfect (not equivalent to the 2-partition) but works fairly well, and again means just $K-1$ split points.

- This is used in `ranger` in R.
]

.right-plot[
```{r}
tab4 <- tab3 |> pivot_longer(-allele) |> group_by(allele) |> mutate(value = round(value/sum(value),2)) |>
  pivot_wider() |> as.data.frame()

tab4 |> knitr::kable()
```
]

---

.left-code[
## More than 2 sources

- Coppersmith (1999) extended this to multiple sources.

- Order by the scores of the first principal component of the proportioned contingency table.

- It's not perfect (not equivalent to the 2-partition) but works fairly well, and again means just $K-1$ split points.

- This is used in `ranger` in R.
]

.right-plot[
```{r}
tab4pc <- prcomp(tab4 |> select(A:C))

dx <- tab4pc$rotation[1,1]/3
dy <- tab4pc$rotation[2,1]/3
ggplot(tab4) +
  geom_point(aes(x=A, y=B)) +
  geom_text(aes(x=A, y=B, label=allele), nudge_x=0.015, nudge_y=0.015) +
  geom_segment(aes(x=mean(A)-dx, y=mean(B)-dy, xend=mean(A)+dx,
                   yend=mean(B)+dy), col='darkred',
               arrow = arrow(length=unit(0.1, "inches"), type="closed", ends="both")) +
  annotate("text", x=mean(tab4$A)+0.02, y=mean(tab4$B)+0.02, label="PC1", col="darkred") +
  labs(x = "P(class A)", y = "P(class B)")
```
]


---

## More than 2 sources

.left-code[
- Coppersmith (1999) extended this to multiple sources.

- Order by the scores of the first principal component of the proportioned contingency table.

- It's not perfect (not equivalent to the 2-partition) but works fairly well, and again means just $K-1$ split points.

- This is used in `ranger` in R.
]

.right-plot[
```{r}
tab4pc <- prcomp(tab4 |> select(A:C))

tab4 |> mutate(order = tab4pc$x[,1]) |>
  arrange(order) |>
  select(-order) |>
  knitr::kable()
```
]

---

.left-code-wide[
## Random forest fit

- Split the source data into 5 sets.

- Use cross-validation to assess performance (sensitivity).

- Does well with poultry, less well with sheep and beef.
]

.right-plot-narrow[
```{r, fig.dim=c(3.2,4.8)}
bias <- read_csv("data/forest/bias.csv") |>
  mutate(prediction = as_factor(prediction), Source = as_factor(Source))
bias |> filter(uses_unique == "No", Ordering == "Poultry", method=="ranger") |>
  ggplot() +
  geom_point(aes(x=prediction, y=prop, shape=Source==prediction, col=Source)) +
  geom_line(aes(x=as.numeric(prediction), y=prop, group=Fold), alpha=0.2) +
  facet_wrap(vars(Source), ncol=1) +
  scale_y_continuous(limits=c(0,1)) +
  scale_shape_manual(values = c("circle filled", "circle")) +
  guides(shape = 'none', colour='none') +
  labs(x=NULL, y="Proportion") +
  scale_colour_manual(values = source_cols2)
```
]

---


.left-code-wide[
## Random forest fit

- Split the source data into 5 sets.

- Use cross-validation to assess precision.

- Does well with poultry, less well with sheep and beef.

- For the isolates with unique alleles, poultry still gets assigned well.
]

.right-plot-narrow[
```{r, fig.dim=c(3.2,4.8)}
bias |> filter(uses_unique == "Yes", Ordering == "Poultry", method=="ranger") |>
  ggplot() +
  geom_point(aes(x=prediction, y=prop, shape=Source==prediction, col=Source)) +
  geom_line(aes(x=as.numeric(prediction), y=prop, group=Fold), alpha=0.2) +
  facet_wrap(vars(Source), ncol=1) +
  scale_y_continuous(limits=c(0,1)) +
  scale_shape_manual(values = c("circle filled", "circle")) +
  guides(shape = 'none', colour='none') +
  labs(x=NULL, y="Proportion") +
  scale_colour_manual(values = source_cols2)
```
]

---


.left-code-wide[
## Random forest fit

- Split the source data into 5 sets.

- Use cross-validation to assess precision.

- Does well with poultry, less well with sheep and beef.

- For the isolates with unique alleles, poultry still gets assigned well.

- If we change the order of the sources though, poultry does much worse!
]

.right-plot-narrow[
```{r, fig.dim=c(3.2,4.8)}
bias |> filter(uses_unique == "Yes", Ordering == "Sheep", method=="ranger") |>
  ggplot() +
  geom_point(aes(x=prediction, y=prop, shape=Source==prediction, col=Source)) +
  geom_line(aes(x=as.numeric(prediction), y=prop, group=Fold), alpha=0.2) +
  facet_wrap(vars(Source), ncol=1) +
  scale_y_continuous(limits=c(0,1)) +
  scale_shape_manual(values = c("circle filled", "circle")) +
  guides(shape = 'none', colour='none') +
  labs(x=NULL, y="Proportion") +
  scale_colour_manual(values = source_cols2)
```
]

---

## What is going on?

- Ranger orders using the Coppersmith method, and new levels are added to the end of the table.

- This associates new levels with the first source: changing the order of the outcome class then changes this association.

```{r, fig.dim=c(10, 3.5)}
bias |> filter(uses_unique == "Yes", method=="ranger") |>
  mutate(Ordering = paste(Ordering, "first")) |>
  ggplot() +
  geom_point(aes(x=prediction, y=prop, shape=Source==prediction, col=Source)) +
  geom_line(aes(x=as.numeric(prediction), y=prop, group=Fold), alpha=0.2) +
  facet_grid(vars(Source), vars(Ordering)) +
  scale_y_continuous(limits=c(0,1)) +
  scale_shape_manual(values = c("circle filled", "circle")) +
  guides(shape = 'none', colour='none') +
  labs(x=NULL, y="Proportion") +
  scale_colour_manual(values = source_cols2)
```

---

## Where should unique alleles be in the table?

- If we assume apriori that each source is equally likely for unique alleles, then they get a PCA score of 0.

- Inserting them at correct place in the table, rather than at the end, eliminates the bias towards the first source.

```{r, fig.dim=c(10, 3.5)}
bias |> filter(uses_unique == "Yes") |>
  mutate(Ordering = paste(Ordering, "first")) |>
  arrange(desc(method)) |>
  ggplot() +
  geom_point(aes(x=prediction, y=prop, shape=Source==prediction, col=method, alpha=method)) +
  geom_line(aes(x=as.numeric(prediction), y=prop, group=paste(Fold, method), col=method, alpha=method), size=0.1) +
  facet_grid(vars(Source), vars(Ordering)) +
  scale_y_continuous(limits=c(0,1)) +
  scale_shape_manual(values = c("circle filled", "circle")) +
  scale_colour_manual(values = c(CA = "darkred", ranger="black")) +
  scale_alpha_manual(values = c(CA = 1, ranger=0.2)) +
  guides(shape = 'none', colour='none', alpha='none') +
  labs(x=NULL, y="Proportion")
```

---

class: middle, inverse

# Encoding  by genetic distance

---

## Encode by genetic distance
.left-code[

- We have the sequences of each allele.

- So we know how close each allele is to each other genetically.

- Genetic closeness may be associated with likelihood of being observed on the same source.
]

.right-plot[
```{r}
pco_dist <- read_csv("data/forest/pco_dist.csv")
pco_dist |>
  pivot_wider(names_from='allele2', values_from=distance) |>
  tibble::column_to_rownames('allele') |>
  knitr::kable()
```
]

---

.left-code-wide[
## Encode by genetic distance

- We have the sequences of each allele.

- So we know how close each allele is to each other genetically.

- Genetic closeness may be associated with likelihood of being observed on the same source.

- Use genetic distance to encode order via **principal coordinate ordination (PCO)**.
]

.right-plot-narrow[
```{r, fig.dim=c(3.2,4.8)}
dat <- read_csv("data/forest/pco_coords.csv")
edge_dat <- dat |> cross_join(dat |> select(allele2=allele, y1=x1,y2=x2)) |>
  filter(x1 < y1) |>
  left_join(pco_dist)

ggplot(dat |> filter(allele != "13")) +
  geom_point(aes(x=x1, y=x2)) +
  geom_text(aes(x=x1, y=x2, label=allele), nudge_x=1, nudge_y=1) +
  geom_segment(data=edge_dat |> filter(allele != "13", allele2 != "13"), aes(x=x1, y=x2, xend=y1, yend=y2), alpha=0.1) +
  coord_equal(xlim=c(-12,15), ylim=c(-26,21)) +
  theme(axis.ticks = element_blank(),
        axis.text = element_blank(),
        axis.title = element_blank())
```
]

---

.left-code-wide[
## Encode by genetic distance

- We have the sequences of each allele.

- So we know how close each allele is to each other genetically.

- Genetic closeness may be associated with likelihood of being observed on the same source.

- Use genetic distance to encode order via **principal coordinate ordination (PCO)**.
]

.right-plot-narrow[
```{r, fig.dim=c(3.2,4.8)}
datpc <- prcomp(dat |> select(x1,x2))

dx <- datpc$rotation[1,1]*20
dy <- datpc$rotation[2,1]*20
pc_x1 <- mean(dat$x1) -dx
pc_x2 <- mean(dat$x1) +dx
pc_y1 <- mean(dat$x2) -dy
pc_y2 <- mean(dat$x2) +dy

ggplot(dat |> filter(allele != "13")) +
  geom_point(aes(x=x1, y=x2)) +
  geom_text(aes(x=x1, y=x2, label=allele), nudge_x=1, nudge_y=1) +
  geom_segment(aes(x=pc_x1, y=pc_y1, xend=pc_x2,
                   yend=pc_y2), col='darkred',
               arrow = arrow(length=unit(0.1, "inches"), type="closed", ends="both")) +
  annotate("text", x=mean(dat$x1)+3, y=mean(dat$x2)-1, label="PCO1", col="darkred") +
  coord_equal(xlim=c(-12,15), ylim=c(-26,21)) +
  theme(axis.ticks = element_blank(),
        axis.text = element_blank(),
        axis.title = element_blank())
```
]

---

.left-code-wide[
## Encode by genetic distance

- We have the sequences of each allele.

- So we know how close each allele is to each other genetically.

- Genetic closeness may be associated with likelihood of being observed on the same source.

- Use genetic distance to encode order via principal coordinate ordination (PCO).

- **For new alleles we compute the distance to observed alleles to place them in PCO space and thus order them correctly.**
]

.right-plot-narrow[
```{r, fig.dim=c(3.2,4.8)}
ggplot(dat) +
  geom_point(aes(x=x1, y=x2, col=allele == "13")) +
  geom_text(aes(x=x1, y=x2, label=allele, col=allele=="13"), nudge_x=1, nudge_y=1) +
  geom_segment(aes(x=pc_x1, y=pc_y1, xend=pc_x2,
                   yend=pc_y2), col='darkred',
               arrow = arrow(length=unit(0.1, "inches"), type="closed", ends="both"),
               alpha=0.5) +
  annotate("text", x=mean(dat$x1)+3, y=mean(dat$x2)-1, label="PCO1", col="darkred") +
  geom_segment(data=edge_dat |> filter(allele == "13" | allele2 == "13"),
               aes(x=x1, y=x2, xend=y1, yend=y2), col='steelblue') +
  guides(colour = 'none') +
  scale_colour_manual(values = c('black', 'steelblue')) +
  coord_equal(xlim=c(-12,15), ylim=c(-26,21)) +
  theme(axis.ticks = element_blank(),
        axis.text = element_blank(),
        axis.title = element_blank())
```
]

---

.left-code[
## Encode by genetic distance

- The ordering now no longer depends on the target source, so there is no potential for the bias seen with target encoding.

- Genetic encoding places each unique allele where it best fits based on distance to existing alleles, rather than treating them all the same like target encoding.

- But, if genetic closeness does not associate with source closeness, we may not get a better result.
]

.right-plot[
```{r}
pco_cap <- read_csv("data/forest/cap_pco.csv") |>
  mutate(prediction = as.factor(prediction))
pco_cap |> filter(Ordering == "Sheep") |>
  group_by(method, Source, prediction) |>
  summarise(n = sum(n), N = sum(N), prop = n/N) |>
  ungroup() |>
  mutate(method = fct_recode(method, `Target encoding` = "CA",
                           `Genomic encoding` = "PCO")) |>
  ggplot() +
  geom_point(aes(x=prediction, y=prop, col=method), position=position_dodge(width=0.2)) +
#  geom_line(aes(x=as.numeric(prediction), y=prop, group=paste(method), col=method), alpha=0.2) +
#  facet_wrap(vars(uses_unique)) +
  scale_y_continuous(limits=c(0,1)) +
  scale_colour_manual(values=c("black", "darkred")) +
  labs(x=NULL, y="Sensitivity", col=NULL) +
  theme(legend.position = 'bottom')
```
]

---

.left-code[
## Source Attribution

- Lots of the human isolates have unique alleles.

- For isolates with many unique alleles, the PCO method produces consistent predictions between trees that utilise the unique alleles and trees that don't.

- The distance measure is only using SNPs. Perhaps there's room to improve this?
]

.right-plot[
```{r}
attr <- read_csv("data/forest/attribution.csv") |>
  mutate(prediction = as.factor(prediction)) |>
  mutate(uses_unique = uses_unique > 0) |>
  group_by(method, row, uses_unique) |>
  count(prediction) |>
  add_tally(n)

rows <- attr |>
  filter(uses_unique, nn > 300) |> pull(row) |> unique()

attr |> filter(row %in% rows) |>
  slice_max(n, n=1) |>
  ungroup() |>
  mutate(method = fct_recode(method, `Target encoding` = "ca",
                             `Genomic encoding` = "pco")) |>
  group_by(method, uses_unique) |>
  count(prediction) |> mutate(prop = n/sum(n)) |>
  ungroup() |>
  mutate(unique = case_when(uses_unique ~ "Unique alleles", TRUE ~ "Observed alleles")) |>
  ggplot() + 
  geom_point(aes(x=prediction, y=prop, col=unique), position=position_dodge(width=0.2)) +
  scale_color_manual(values = c('steelblue', 'brown')) +
  facet_wrap(vars(method)) +
  labs(x=NULL, y="Proportion of Human Cases", col=NULL) +
  theme(legend.position='bottom')
```
]

---

## Summary

- Using more genes for source attribution doesn't necessarily help.

- Models need to cope with lots of high cardinality categorical variables, with many levels unique to the test set.

- Existing models break in ways that are sometimes subtle!

- Paper: Lost in the Forest (H.L. Smith) https://www.biorxiv.org/content/10.1101/2022.09.12.507676v1

    - Demonstrates existing encoding methods are biased, and presents a solution.
    - Shows how to use auxiliary information for the absent levels.

---

class: middle, inverse

# Questions?
